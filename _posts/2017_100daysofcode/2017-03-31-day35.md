---
layout: post
author: csiu
date: 2017-03-31
title: "Day35: Using connection weights"
categories: update
tags:
  - 100daysofcode
  - machine-learning
excerpt: Trying connection weights for variable importance
---
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

Today I want to implement the other algorithm for measuring feature importance, connection weights.

> Ibrahim, OM. 2013. [A comparison of methods  for  assessing the  relative  importance of input variables in  artificial neural networks](http://www.palisade.com/downloads/pdf/academic/DTSpaper110915.pdf). Journal of Applied Sciences Research, 9(11): 5692-5700.

The Jupyter Notebook for this little project is found [here](https://nbviewer.jupyter.org/github/csiu/100daysofcode/blob/master/nn/day35_connection-weights.ipynb).

### Connection weights

<img src="{{ site.baseurl }}/img/figure/2017-03-31/cw.png" style="display: block; margin: auto; width: 99%" />

Connection weights calculate the sum of products from the input to the output.

### Implementing the Connection Weights Algorithm (CW)

```python
def connection_weights(A, B):
    """
    Computes Connection weights algorithm
    A = matrix of weights of input-hidden layer (rows=input & cols=hidden)
    B = matrix of weights of hidden-output layer (rows=hidden & cols=output)
    """    
    cw = np.dot(A, B)

    # normalize to 100% for relative importance
    ri = cw / cw.sum()
    return(ri)
```

<br>

### Visualizing variable importance by CW

<img src="{{ site.baseurl }}/img/figure/2017-03-31/box.png" style="display: block; margin: auto; width: 99%" />

<img src="{{ site.baseurl }}/img/figure/2017-03-31/line.png" style="display: block; margin: auto; width: 99%" />

Similar to Garson's algorithm, the weight of input features across the hidden nodes are variable for some features than others (BOX PLOT); but unlike Garson's algorithm, the feature importance for the different output classes are not the same (LINE PLOT).

<img src="{{ site.baseurl }}/img/figure/2017-03-31/bar.png" style="display: block; margin: auto;" />

Partitioning the input features to the class whose feature importance is the greatest, we find the features not uniformly distributed across the index of the output classes (BAR PLOT).
