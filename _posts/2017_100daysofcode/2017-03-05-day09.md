---
layout: post
author: csiu
date: 2017-03-05
title: "Day09: Back to Kaggle and neural networks"
categories: update
tags:
  - 100daysofcode
  - machine-learning
  - kaggle
excerpt: Using neural networks from Scikit-learn
---

On [Day02]({{ site.baseurl }}/update/2017/02/26/day02.html), I tried to implement a 2-layer fully connected neural network from scratch. Evaluation by Kaggle was 0.59330. Today I want to use neural networks from Scikit-learn to train a model for the [Digit Recognizer](https://www.kaggle.com/c/digit-recognizer/data) Kaggle competition.

The Jupyter Notebook for this little project is found [here](https://nbviewer.jupyter.org/github/csiu/kaggle/blob/master/digit_recognizer/DigitRecognizer-neuralnetwork.ipynb).

### Approach

1. Train on 80% (n = 33,600)
2. Validate on remaining 20% (n = 8,400)
3. Submit predictions to Kaggle

In total there is 784 features and 42,000 training samples.

### Neural Network / Multi-layer Perceptron classifier

```python
from sklearn.neural_network import MLPClassifier

clf = MLPClassifier()
clf.fit(X_train, y_train)
```

The Scikit-learn documentation for the Multi-layer Perceptron classifier is found [here](http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier). The `MLPClassifier()` arguments I use include:

- `alpha` which specifies the L2 penalty (regularization term) parameter
- `hidden_layer_sizes` which specifies the number of hidden layers and the number of nodes in each layer
- `random_state` which is a seed for the random number generator (ie. for reproducible results)

### Specifying the hidden layer

In implementing a neural network, we need to specify the hidden layer (eg. How many layers? And how many nodes in each layer?). According to [doug (2010)](http://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw):

> In sum, for most problems, one could probably get decent performance (even without a second optimization step) by setting the hidden layer configuration using just two rules: (i) number of **hidden layers equals one**; and (ii) the number of neurons in that layer is the **mean of the neurons in the input and output** layers.

Thus our neural network is as follows:

- 1 input layer: 784 nodes (one node for each input feature)
- 1 hidden layer: 397 nodes (mean of 784 and 10)
- 1 output layer: 10 nodes (one for each output class)

When we plot the weights between the nodes in the input (x-axis) and hidden (y-axis) layer, we find that some features more informative than others.

<img src="{{ site.baseurl }}/img/figure/2017-03-05/day09_1.png" style="display: block; margin: auto; width: 95%" />

### Evaluation

Validating the model on the remaining part of the training data, we find the accuracy to be 96.5%. Submitting the predictions to Kaggle, the submission scored 0.96214 (which is an improvement on the previous score of [0.95871]({{ site.baseurl }}/update/2017/03/01/day05.html) using random forest).

### Training on the whole set

When we retrain a new neural network on all data, the score improved to 0.96400 (+0.00529). When we counted the number of labels differing between the two sets of predictions, we have 1182 differences.


<img src="{{ site.baseurl }}/img/figure/2017-03-05/day09_2.png" style="display: block; margin: auto; width: 95%" />
<img src="{{ site.baseurl }}/img/figure/2017-03-05/day09_3.png" style="display: block; margin: auto; width: 95%" />

From the plots, we find that most inconsistent labels are between predicting 4 and 9. *Understandable. Some people's 4s look like 9s and 9s look like 4s.* We also learn that training on all data is more accurate than training on a portion of the data.
