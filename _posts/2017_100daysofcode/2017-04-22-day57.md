---
layout: post
author: csiu
date: 2017-04-22
title: "Day57: Caching results"
categories: update
tags:
  - 100daysofcode
excerpt: 30 times faster
---

Running [the script]({{ site.baseurl }}/update/2017/04/21/day56.html) takes 10 minutes. And this is *too slow*, especially when I want to find the similar documents of different documents. Today I implement a **caching** system to store the preprocessed results.

<div style="color:grey; padding-left:2em">
<ol>
<li>Get data</li>
<li>Preprocess documents <-- bottleneck</li>
<li>Count matrix</li>
<li>SVD</li>
<li>Compute distances</li>
</ol>
</div>
<br>

### Caching by saving intermediates

There are a couple ways to save data.

- as a human readable CSV file ([`pandas.DataFrame.to_csv`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_csv.html)), or

```python
df.to_csv(preprocess_file, index=False, sep="\t")
df = pd.read_csv(preprocess_file, sep="\t")
```

- as a binary pickle file ([`pandas.DataFrame.to_pickle`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_pickle.html))

```python
df.to_pickle(preprocess_file+".pkl")
df = pd.read_pickle(preprocess_file+".pkl")
```

<br>
When the two saved files are compared, I found both are 34M in size according to `ls -lh`. However, when I try to load and use the CSV file in Python, I get an error complaining about value types.

```
ValueError: np.nan is an invalid document, expected byte or unicode string.
```

As a result, I used the pickled file in production (see script: [`ea60d03`]([https://github.com/csiu/kick/blob/ea60d03384829cc988029baa134ba83fdcdee467/src/python/sim_doc.py); [diff](https://github.com/csiu/kick/commit/ea60d03384829cc988029baa134ba83fdcdee467)).

<br>

### How well did I do?

Originally, the script took 10 minutes to run. Now it takes 20 seconds. We have made the script 30 times faster (for subsequent runs).

*Much better.*
