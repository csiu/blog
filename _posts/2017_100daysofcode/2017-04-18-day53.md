---
layout: post
author: csiu
date: 2017-04-18
title: "Day53: SVD in Scikit-learn"
categories: update
tags:
  - 100daysofcode
  - machine-learning
excerpt: It doesn't crash!
---
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

A couple days ago, I was trying to factorize a document-word count matrix with SVD. However (during the factorization step), my job kept on crashing because the $$177140 \times 99946$$ matrix was too big.

<blockquote class="twitter-tweet" data-lang="en" align="center"><p lang="en" dir="ltr">Attempting matrix factorization with SVD in <a href="https://twitter.com/hashtag/Python?src=hash">#Python</a>. Day51 of <a href="https://twitter.com/hashtag/100daysofcode?src=hash">#100daysofcode</a>. <a href="https://twitter.com/hashtag/datascience?src=hash">#datascience</a> <a href="https://t.co/08IKBoFjKM">https://t.co/08IKBoFjKM</a> <a href="https://t.co/mO9Wz9lHqm">pic.twitter.com/mO9Wz9lHqm</a></p>&mdash; Celia S. Siu (@celiassiu) <a href="https://twitter.com/celiassiu/status/853898701898629120">April 17, 2017</a></blockquote>

On twitter, Jake suggested to check out Scikit-learn.

<blockquote class="twitter-tweet" data-conversation="none" data-lang="en" align="center"><p lang="en" dir="ltr"><a href="https://twitter.com/celiassiu">@celiassiu</a> Check out the irlba R library as well or scikit learn</p>&mdash; Jake Lever (@jakelever0) <a href="https://twitter.com/jakelever0/status/854043620244049920">April 17, 2017</a></blockquote> <script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

The Jupyter Notebook for this little project is found [here](https://nbviewer.jupyter.org/github/csiu/kick/blob/master/src/ipynb/day53_svd2.ipynb).

<br>

### SVD with Scikit-learn

In Scikit-learn, [sklearn.decomposition.TruncatedSVD](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html) is used to compute SVD.

<a href="http://scikit-learn.org/stable/modules/decomposition.html#truncated-singular-value-decomposition-and-latent-semantic-analysis" target="_blank"><img src="{{ site.baseurl }}/img/figure/2017-04-18/day53.png" style="display:block; margin:auto; width:80%;" /></a>

Applying the `TruncatedSVD` to our matrix for 100 components, it works!

```python
from sklearn.decomposition import TruncatedSVD

svd = TruncatedSVD(n_components=100, random_state=5)
svd.fit(X)
```

However, the $$U$$, $$\Sigma$$, and $$V$$ matrices are not returned (only the somewhat reconstructed one with $$k$$ components).

<br>

### Getting $$U$$, $$\Sigma$$, and $$V$$

According [maxymoo on stackoverflow (2015)](http://stackoverflow.com/questions/31523575/get-u-sigma-v-matrix-from-truncated-svd-in-scikit-learn), `TruncatedSVD` is a wrapper and `sklearn.utils.extmath.randomized_svd` can be used to manually call SVD.

```python
from sklearn.utils.extmath import randomized_svd

U, s, Vh = randomized_svd(X, n_components=100, n_iter=5, random_state=5)
```

> **extmath.randomized_svd**: compute the k-truncated randomized SVD. This algorithm finds the exact truncated singular values decomposition using randomization to speed up the computations. It is particularly fast on large matrices on which you wish to extract only a small number of components.\\
> [http://scikit-learn.org/stable/developers/utilities.html](http://scikit-learn.org/stable/developers/utilities.html)

<br>

### Future work

Now that I have $$U$$, $$\Sigma$$, and $$V$$, I can investigate questions such as *given a document, what is the most similar document to it in the corpus*.
